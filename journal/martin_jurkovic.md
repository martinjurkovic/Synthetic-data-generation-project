# Martin Jurkovic's Data Science Project Competition journal

## February 2023 (1h)
* 23. (1h): Meeting with company ZCAM. 

## March 2023 (41.5h)
* 3. (2h): Meeting with mentor Strumbelj Erik. Work outline and project kickoff.
* 9. (10h): Initial paper research
* 16. (8h): More paper research and initial code implementations
* 17. (1.5h): Meeting with mentor Strumbelj Erik.
* 23. (10h): Data generation implementations and initial visualizations
* 24. (1h): Meeting with mentor Strumbelj Erik.
* 30. (8h): Visualizations and evaluation (metrics) for all implemented methods on rossman dataset

## April 2023 (52h)
* 6. (8h): Energy statistics literature review and multicolumn visualizations
* 10. (10h): Energy statistic implementation, interim report
* 12. (1h): Meeting with mentor Strumbelj Erik, interim report review, project outline review
* 13. (8h): Interim report corrections, dataset collection for data splits, data generation (Gretelai sql)
* 19. (8h): Metric research for evaluation, contact with companies for commercial dataset generation, metric descriptions and understanding
* 24. (1h): Meeting with mentor Strumbelj Erik, further work outline
* 26. (8h): K-fold splitting of biodegradability hierarchical data, start of SDV data generation
* 27. (10h): data splitting fixes, SDV data generation, evaluation report, python package creation
* 29. (3h): Meeting with mentor Strumbelj Erik, meeting between teammates for further work

## May 2023 (96)
* 3. (8h): Commercial tools for data generation: generating and research on google colab
* 6. (8h): Finish data splitting, add discriminative detection models for evaluation
* 18. (8h): Implementing RCTGAN generation and supporting HPC generation
* 19. (8h): RCTGAN, Gretel and Mostlyai data generation
* 20. (8h): Gretel, REalTabFormer Generation HPC
* 21. (8h): Metrics and evaluation protocol updates
* 22. (8h): PostgreSQL setup for mostlyai, conditional sampling implementation, meeting with mentor
* 23. (8h): Multi table discriminative detection, meeting for cross-team collaboration
* 24. (8h): CV10 evaluation, fixing bugs and code cleanup, meeting with mentor
* 25. (8h): Baseline implementation, Telstra ML Efficacy,
* 26. (8h): Preparing the final report and running final HPC experiments
* 27. (8h): Full benchmark packaging
* 28. (8h): Final report and visualizations

## Total: 165.5h (full hours)